{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tVWOGeWnVDwH"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q1.  What is hypothesis testing in statistics\n",
        "Ans1. Hypothesis testing in statistics is a method used to make decisions or inferences about population parameters based on sample data. It helps determine whether there is enough statistical evidence to support a specific belief (hypothesis) about a population.\n",
        "\n",
        "Key Terms\n",
        "Null Hypothesis (H₀):\n",
        "A default assumption that there is no effect or no difference.\n",
        "Alternative Hypothesis (H₁ or Ha):\n",
        "A claim that contradicts the null hypothesis.\n",
        "\n",
        "\n",
        "Q2.  What is the null hypothesis, and how does it differ from the alternative hypothesis\n",
        "\n",
        "Ans2. Null Hypothesis vs. Alternative Hypothesis\n",
        "\n",
        "\n",
        "1. Null Hypothesis (H₀):\n",
        "A default assumption or claim that there is no effect, no difference, or no relationship in the population.\n",
        "\n",
        "2. Alternative Hypothesis (H₁ or Ha):\n",
        "A statement that contradicts the null hypothesis. It suggests there is an effect, a difference, or a relationship.\n",
        "\n",
        "\n",
        "\n",
        "Q3.  What is the significance level in hypothesis testing, and why is it important\n",
        "\n",
        "Ans3. The significance level (denoted by α) is the threshold you set to determine whether a test result is statistically significant. It represents the probability of rejecting the null hypothesis (H₀) when it is actually true — this is called a Type I error.\n",
        "\n",
        "Common Values of α:\n",
        "Interpretation:\n",
        "If α = 0.05, it means you are willing to accept a 5% chance of making a Type I error.\n",
        "\n",
        "If the p-value ≤ α, you reject H₀ → The result is statistically significant.\n",
        "If the p-value > α, you do not reject H₀ → The result is not statistically significant.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Q4.  What does a P-value represent in hypothesis testing\n",
        "\n",
        "Ans4. The p-value is a number that helps you decide whether to reject the null hypothesis (H₀).\n",
        "\n",
        "The p-value is the probability of obtaining the observed results, or something more extreme, assuming that the null hypothesis (H₀) is true.\n",
        "\n",
        "\n",
        "\n",
        "Q5.  How do you interpret the P-value in hypothesis testing\n",
        "\n",
        "Ans5. The p-value tells you how likely your sample result is if the null hypothesis (H₀) were true. It guides your decision to reject or not reject H₀.\n",
        "\n",
        "\n",
        "| **p-value** | **Interpretation**             | **Decision**         |\n",
        "| ----------- | ------------------------------ | -------------------- |\n",
        "| **p ≤ α**   | Strong evidence **against** H₀ | **Reject H₀**        |\n",
        "| **p > α**   | Not enough evidence against H₀ | **Do not reject H₀** |\n",
        "\n",
        "\n",
        "Q6.  What are Type 1 and Type 2 errors in hypothesis testing\n",
        "\n",
        "Ans6. Type I and Type II Errors in Hypothesis Testing\n",
        "In hypothesis testing, errors can occur when making decisions based on sample data. These are categorized as Type I and Type II errors.\n",
        "\n",
        "1. Type I Error (False Positive)\n",
        "2. Type II Error (False Negative)\n",
        "Definition: Not rejecting H₀ when the alternative hypothesis (H₁) is actually true.\n",
        "\n",
        "| Verdict          | Reality: Innocent (H₀ true) | Reality: Guilty (H₁ true) |\n",
        "| ---------------- | --------------------------- | ------------------------- |\n",
        "| Found guilty     | ❌ Type I Error              | ✅ Correct decision        |\n",
        "| Found not guilty | ✅ Correct decision          | ❌ Type II Error           |\n",
        "\n",
        "\n",
        "\n",
        "Q7.  What is the difference between a one-tailed and a two-tailed test in hypothesis testing\n",
        "\n",
        "Ans7. The difference between one-tailed and two-tailed tests lies in the direction of the alternative hypothesis (H₁) and what you are testing for.\n",
        "\n",
        "\n",
        "1. One-Tailed Test\n",
        "2. Two-Tailed Test\n",
        "\n",
        "\n",
        "| Feature           | One-Tailed Test                    | Two-Tailed Test                          |\n",
        "| ----------------- | ---------------------------------- | ---------------------------------------- |\n",
        "| Direction of H₁   | μ > μ₀ or μ < μ₀                   | μ ≠ μ₀                                   |\n",
        "| Area of rejection | Only one tail (left or right)      | Both tails of the distribution           |\n",
        "| More sensitive to | Changes in **one direction**       | Changes in **either direction**          |\n",
        "| p-value           | Calculated for **one side**        | Calculated for **both sides**            |\n",
        "| Common use cases  | Quality control, threshold testing | Effect detection without known direction |\n",
        "\n",
        "\n",
        "Q8.  What is the Z-test, and when is it used in hypothesis testing\n",
        "\n",
        "\n",
        "Ans8. The Z-test is a statistical test used to determine whether there is a significant difference between sample and population means or between two sample means, when the population standard deviation (σ) is known and the sample size is large (usually n ≥ 30).\n",
        "\n",
        "| Condition                                  | Reason                        |\n",
        "| ------------------------------------------ | ----------------------------- |\n",
        "| Population standard deviation (σ) is known | Required for Z-test formula   |\n",
        "| Sample size is large (n ≥ 30)              | Central Limit Theorem applies |\n",
        "| Data is approximately normally distributed | Needed for accurate z-scores  |\n",
        "\n",
        "\n",
        "Q9.  How do you calculate the Z-score, and what does it represent in hypothesis testing\n",
        "\n",
        "Ans9.\n",
        "A Z-score (also called a standard score) tells you how many standard deviations a data point or sample statistic is from the population mean.\n",
        "\n",
        "\n",
        "In hypothesis testing, the Z-score helps you determine whether your sample result is significantly different from the null hypothesis.\n",
        "\n",
        "| **Z-score** | **Interpretation**            |                      |                                                     |\n",
        "| ----------- | ----------------------------- | -------------------- | --------------------------------------------------- |\n",
        "| **Z = 0**   | Sample mean = population mean |                      |                                                     |\n",
        "| \\*\\*        | Z                             | < critical value\\*\\* | Result is **not significant**, do **not reject H₀** |\n",
        "| \\*\\*        | Z                             | ≥ critical value\\*\\* | Result is **significant**, **reject H₀**            |\n",
        "\n",
        "\n",
        "Q10. What is the T-distribution, and when should it be used instead of the normal distribution\n",
        "\n",
        "Ans10. The T-distribution (Student's t-distribution) is a probability distribution used in statistical analysis, especially when:\n",
        "\n",
        "The sample size is small (typically n < 30)\n",
        "\n",
        "The population standard deviation (σ) is unknown\n",
        "\n",
        "When to Use the T-distribution Instead of the Normal Distribution\n",
        "\n",
        "\n",
        "| Condition                                        | Explanation                                       |\n",
        "| ------------------------------------------------ | ------------------------------------------------- |\n",
        "| ✅ Population standard deviation is **unknown**   | You use the sample standard deviation (s) instead |\n",
        "| ✅ Sample size is **small** (n < 30)              | The Central Limit Theorem may not apply yet       |\n",
        "| ✅ Data is **approximately normally distributed** | Especially important for small samples            |\n",
        "\n",
        "\n",
        "Q11.  What is the difference between a Z-test and a T-test\n",
        "\n",
        "Ans11.\n",
        "\n",
        "| Feature                    | **Z-test**                                    | **T-test**                                                                 |\n",
        "| -------------------------- | --------------------------------------------- | -------------------------------------------------------------------------- |\n",
        "| **Population SD (σ)**      | Known                                         | Unknown (uses sample SD $s$)                                               |\n",
        "| **Sample Size (n)**        | Large (typically $n \\geq 30$)                 | Small or any size (especially $n < 30$)                                    |\n",
        "| **Distribution Used**      | Normal (Z) distribution                       | Student’s t-distribution                                                   |\n",
        "| **Test Statistic Formula** | $Z = \\frac{\\bar{X} - \\mu}{\\sigma/\\sqrt{n}}$   | $t = \\frac{\\bar{X} - \\mu}{s/\\sqrt{n}}$                                     |\n",
        "| **Shape of Distribution**  | Standard normal curve (fixed)                 | Bell-shaped with heavier tails; depends on degrees of freedom (df = $n-1$) |\n",
        "| **When to Use**            | When σ is known and sample size is large      | When σ is unknown or sample size is small                                  |\n",
        "| **Example Use Cases**      | Quality control, large sample mean comparison | Small sample studies, estimating means from unknown σ                      |\n",
        "\n",
        "Q12.  What is the T-test, and how is it used in hypothesis testing\n",
        "\n",
        "\n",
        "Ans12. The T-test is a statistical method used to determine whether there is a significant difference between the means of two groups or between a sample mean and a known value, especially when the population standard deviation (σ) is unknown and/or the sample size is small.\n",
        "\n",
        "It uses the t-distribution to account for the added uncertainty from estimating the population standard deviation with the sample standard deviation.\n",
        "\n",
        "Summary\n",
        "The T-test is used when the population SD is unknown and/or sample size is small.\n",
        "\n",
        "It tests hypotheses about means by comparing the t-statistic to critical values or p-values from the t-distribution.\n",
        "\n",
        "It has different variants for one sample, two independent samples, and paired samples.\n",
        "\n",
        "\n",
        "\n",
        "Q13. What is the relationship between Z-test and T-test in hypothesis testing\n",
        "\n",
        "Ans13.Both Z-test and T-test are used to test hypotheses about population means, but they differ mainly based on what you know about the population standard deviation and sample size. Their relationship can be summarized as:\n",
        "\n",
        "| Condition                               | Use Z-test     | Use T-test                                 |\n",
        "| --------------------------------------- | -------------- | ------------------------------------------ |\n",
        "| Population standard deviation (σ) known | ✔ Yes          | ✘ No                                       |\n",
        "| Population standard deviation unknown   | ✘ No           | ✔ Yes                                      |\n",
        "| Sample size                             | Large (n ≥ 30) | Small (n < 30), or any size when σ unknown |\n",
        "| Sample standard deviation               | Not needed     | Required (sample SD used as estimate)      |\n",
        "\n",
        "\n",
        "Q14.  What is a confidence interval, and how is it used to interpret statistical results\n",
        "\n",
        "Ans14.A confidence interval (CI) is a range of values, calculated from sample data, that is likely to contain the true population parameter (such as the mean or proportion) with a specified level of confidence.\n",
        "\n",
        "ExampleYou estimate the average height of a population from a sample and get:\n",
        "\n",
        "\\bar{X} = 170 \\text{ cm}, \\quad \\text{95% CI} = (165, 175) \\text{ cm}\n",
        "You interpret this as being 95% confident the true average height is between 165 cm and 175 cm.\n",
        "\n",
        "\n",
        "\n",
        "Q15.  What is the margin of error, and how does it affect the confidence interval\n",
        "\n",
        "Ans15. The margin of error is the amount added and subtracted from the sample estimate to create the confidence interval. It represents the maximum expected difference between the sample statistic and the true population parameter, reflecting the uncertainty in the estimate.\n",
        "\n",
        "Formula for Margin of Error\n",
        "Margin of Error=(Critical value)×(Standard Error)\n",
        "Summary\n",
        "The margin of error quantifies the uncertainty around the sample estimate.\n",
        "\n",
        "It directly controls the width of the confidence interval.\n",
        "\n",
        "Controlling MoE helps balance precision and confidence in statistical results.\n",
        "\n",
        "\n",
        "\n",
        "Q16.  How is Bayes' Theorem used in statistics, and what is its significance\n",
        "\n",
        "Ans16. Bayes’ Theorem is a fundamental rule in probability theory that describes how to update the probability of a hypothesis based on new evidence.\n",
        "\n",
        "Significance of Bayes’ Theorem\n",
        "Provides a formal framework to combine prior knowledge and new evidence.\n",
        "\n",
        "Enables probabilistic reasoning in uncertain situations.\n",
        "\n",
        "Unlike classical (frequentist) methods, it can continuously update probability estimates as more data becomes available.\n",
        "\n",
        "\n",
        "\n",
        "Q17.  What is the Chi-square distribution, and when is it used\n",
        "\n",
        "Ans17.The Chi-square (χ²) distribution is a probability distribution that describes the sum of the squares of independent standard normal random variables. It is asymmetric and skewed to the right, with values only ≥ 0.\n",
        "\n",
        "| Test Type                       | Purpose                                                                                                                                               |\n",
        "| ------------------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------- |\n",
        "| Chi-square Test of Independence | Determine if two categorical variables are related or independent. Example: Is gender independent of voting preference?                               |\n",
        "| Chi-square Goodness-of-Fit      | Assess if observed frequencies match expected frequencies for a categorical variable. Example: Does a dice roll distribution fit uniform expectation? |\n",
        "| Variance Test                   | Test if sample variance differs from a hypothesized population variance.                                                                              |\n",
        "\n",
        "\n",
        "Q18.  What is the Chi-square goodness of fit test, and how is it applied\n",
        "\n",
        "Ans18. The Chi-square goodness of fit test is a statistical test used to determine whether observed categorical data matches an expected distribution.\n",
        "\n",
        "| Face         | 1 | 2  | 3 | 4  | 5  | 6  |\n",
        "| ------------ | - | -- | - | -- | -- | -- |\n",
        "| Observed (O) | 8 | 12 | 9 | 11 | 10 | 10 |\n",
        "\n",
        "\n",
        "Summary\n",
        "The Chi-square goodness of fit test compares observed vs expected frequencies.\n",
        "\n",
        "It helps determine if a categorical variable follows a specific theoretical distribution.\n",
        "\n",
        "\n",
        "\n",
        "Q19.  What is the F-distribution, and when is it used in hypothesis testing\n",
        "\n",
        "Ans19. The F-distribution is a continuous probability distribution that arises when comparing variances of two independent samples. It is the distribution of the ratio of two scaled chi-square variables, each divided by their respective degrees of freedom.\n",
        "\n",
        "\n",
        "| Test                     | Purpose                                                                            |\n",
        "| ------------------------ | ---------------------------------------------------------------------------------- |\n",
        "| **F-test for Variances** | Test $H_0: \\sigma_1^2 = \\sigma_2^2$ vs $H_a: \\sigma_1^2 \\neq \\sigma_2^2$           |\n",
        "| **ANOVA**                | Test if multiple group means are equal, i.e., $H_0: \\mu_1 = \\mu_2 = \\dots = \\mu_k$ |\n",
        "\n",
        "\n",
        "Q20. What is an ANOVA test, and what are its assumptions\n",
        "\n",
        "Ans20. ANOVA (Analysis of Variance) is a statistical method used to compare the means of three or more groups to see if at least one group mean is significantly different from the others.\n",
        "\n",
        "Summary\n",
        "ANOVA tests if multiple groups have the same mean.\n",
        "\n",
        "It uses the F-distribution for hypothesis testing.\n",
        "\n",
        "\n",
        "\n",
        "Q21.  What are the different types of ANOVA tests\n",
        "\n",
        "Ans21. ANOVA has several variations depending on the experimental design and number of factors involved. Here are the main types:\n",
        "\n",
        "1. One-Way ANOVA\n",
        "Purpose: Tests differences in means across one independent categorical variable (factor) with two or more groups.\n",
        "\n",
        "2. Two-Way ANOVA\n",
        "\n",
        "| ANOVA Type              | Factors Involved                      | Design Type      | Example Use Case                             |\n",
        "| ----------------------- | ------------------------------------- | ---------------- | -------------------------------------------- |\n",
        "| One-Way ANOVA           | One categorical independent variable  | Between-subjects | Comparing means of 3 teaching methods        |\n",
        "| Two-Way ANOVA           | Two categorical independent variables | Between-subjects | Effects of diet & exercise on weight         |\n",
        "| Repeated Measures ANOVA | One factor, repeated measurements     | Within-subjects  | Blood pressure measured over time            |\n",
        "| MANOVA                  | Multiple dependent variables          | Between-subjects | Drug effects on blood pressure & cholesterol |\n",
        "\n",
        "\n",
        "Q22. What is the F-test, and how does it relate to hypothesis testing?\n",
        "\n",
        "Ans22. The F-test is a statistical test that uses the F-distribution to compare variances or to assess the overall significance of a model by comparing explained variance to unexplained variance.\n",
        "\n",
        "SummaryThe F-test evaluates whether variances or group means differ significantly.\n",
        "\n",
        "It is fundamental in ANOVA and variance comparison tests.\n",
        "\n",
        "The F-statistic is a ratio of variances, and its distribution depends on two degrees of freedom parameters.\n",
        "\n",
        "\n",
        "Practical\n",
        "\n",
        "Q1.  Write a Python program to perform a Z-test for comparing a sample mean to a known population mean and\n",
        "\n",
        "Ans1. from math import sqrt\n",
        "from scipy.stats import norm\n",
        "\n",
        "def z_test(sample_mean, population_mean, population_std, sample_size, alpha=0.05):\n",
        "    \"\"\"\n",
        "    Performs a one-sample Z-test for the sample mean.\n",
        "\n",
        "    Parameters:\n",
        "    - sample_mean: Mean of the sample\n",
        "    - population_mean: Known population mean\n",
        "    - population_std: Known population standard deviation\n",
        "    - sample_size: Number of observations in the sample\n",
        "    - alpha: Significance level (default 0.05)\n",
        "\n",
        "    Returns:\n",
        "    - z_stat: Calculated Z statistic\n",
        "    - p_value: Two-tailed p-value\n",
        "    - conclusion: Reject or fail to reject null hypothesis\n",
        "    \"\"\"\n",
        "\n",
        "    # Calculate standard error\n",
        "    standard_error = population_std / sqrt(sample_size)\n",
        "\n",
        "    # Calculate Z statistic\n",
        "    z_stat = (sample_mean - population_mean) / standard_error\n",
        "\n",
        "    # Calculate two-tailed p-value\n",
        "    p_value = 2 * (1 - norm.cdf(abs(z_stat)))\n",
        "\n",
        "    # Decision based on p-value\n",
        "    if p_value < alpha:\n",
        "        conclusion = \"Reject the null hypothesis (significant difference).\"\n",
        "    else:\n",
        "        conclusion = \"Fail to reject the null hypothesis (no significant difference).\"\n",
        "\n",
        "    return z_stat, p_value, conclusion\n",
        "\n",
        "\n",
        "# Example usage:\n",
        "sample_mean = 102\n",
        "population_mean = 100\n",
        "population_std = 15\n",
        "sample_size = 36\n",
        "alpha = 0.05\n",
        "\n",
        "z_stat, p_value, conclusion = z_test(sample_mean, population_mean, population_std, sample_size, alpha)\n",
        "\n",
        "print(f\"Z-statistic: {z_stat:.4f}\")\n",
        "print(f\"P-value: {p_value:.4f}\")\n",
        "print(conclusion)\n",
        "\n",
        "\n",
        "Q2.  Simulate random data to perform hypothesis testing and calculate the corresponding P-value using Python\n",
        "\n",
        "Ans2.import numpy as np\n",
        "from scipy.stats import ttest_ind\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "# Simulate data for two groups\n",
        "group1 = np.random.normal(loc=50, scale=5, size=30)  # mean=50, std=5, n=30\n",
        "group2 = np.random.normal(loc=52, scale=5, size=30)  # mean=52, std=5, n=30\n",
        "\n",
        "# Perform two-sample t-test (independent samples)\n",
        "t_stat, p_value = ttest_ind(group1, group2)\n",
        "\n",
        "print(f\"T-statistic: {t_stat:.4f}\")\n",
        "print(f\"P-value: {p_value:.4f}\")\n",
        "\n",
        "# Interpret result\n",
        "alpha = 0.05\n",
        "if p_value < alpha:\n",
        "    print(\"Reject the null hypothesis: groups have significantly different means.\")\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis: no significant difference between group means.\")\n",
        "\n",
        "\n",
        "Q3.  Implement a one-sample Z-test using Python to compare the sample mean with the population mean\n",
        "\n",
        "Ans3. from math import sqrt\n",
        "from scipy.stats import norm\n",
        "\n",
        "def one_sample_z_test(sample_mean, population_mean, population_std, sample_size, alpha=0.05):\n",
        "    \"\"\"\n",
        "    Perform a one-sample Z-test comparing sample mean to population mean.\n",
        "\n",
        "    Parameters:\n",
        "    - sample_mean: Mean of the sample\n",
        "    - population_mean: Known population mean\n",
        "    - population_std: Known population standard deviation\n",
        "    - sample_size: Number of observations in the sample\n",
        "    - alpha: Significance level (default 0.05)\n",
        "\n",
        "    Returns:\n",
        "    - z_stat: Z statistic\n",
        "    - p_value: Two-tailed p-value\n",
        "    - conclusion: Result of hypothesis test\n",
        "    \"\"\"\n",
        "\n",
        "    # Calculate standard error\n",
        "    standard_error = population_std / sqrt(sample_size)\n",
        "\n",
        "    # Calculate Z statistic\n",
        "    z_stat = (sample_mean - population_mean) / standard_error\n",
        "\n",
        "    # Calculate two-tailed p-value\n",
        "    p_value = 2 * (1 - norm.cdf(abs(z_stat)))\n",
        "\n",
        "    # Interpret the result\n",
        "    if p_value < alpha:\n",
        "        conclusion = \"Reject the null hypothesis: significant difference.\"\n",
        "    else:\n",
        "        conclusion = \"Fail to reject the null hypothesis: no significant difference.\"\n",
        "\n",
        "    return z_stat, p_value, conclusion\n",
        "\n",
        "# Example usage\n",
        "sample_mean = 105\n",
        "population_mean = 100\n",
        "population_std = 15\n",
        "sample_size = 40\n",
        "alpha = 0.05\n",
        "\n",
        "z_stat, p_value, conclusion = one_sample_z_test(sample_mean, population_mean, population_std, sample_size, alpha)\n",
        "\n",
        "print(f\"Z-statistic: {z_stat:.4f}\")\n",
        "print(f\"P-value: {p_value:.4f}\")\n",
        "print(conclusion)\n",
        "\n",
        "\n",
        "Q4.  Perform a two-tailed Z-test using Python and visualize the decision region on a plot\n",
        "\n",
        "Ans4. import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import norm\n",
        "from math import sqrt\n",
        "\n",
        "def two_tailed_z_test(sample_mean, population_mean, population_std, sample_size, alpha=0.05):\n",
        "    # Calculate standard error\n",
        "    se = population_std / sqrt(sample_size)\n",
        "\n",
        "    # Calculate Z statistic\n",
        "    z_stat = (sample_mean - population_mean) / se\n",
        "\n",
        "    # Calculate two-tailed p-value\n",
        "    p_value = 2 * (1 - norm.cdf(abs(z_stat)))\n",
        "\n",
        "    # Critical Z values for two-tailed test\n",
        "    z_crit = norm.ppf(1 - alpha/2)\n",
        "\n",
        "    # Decision\n",
        "    reject_null = abs(z_stat) > z_crit\n",
        "\n",
        "    return z_stat, p_value, z_crit, reject_null\n",
        "\n",
        "# Parameters\n",
        "sample_mean = 108\n",
        "population_mean = 100\n",
        "population_std = 15\n",
        "sample_size = 36\n",
        "alpha = 0.05\n",
        "\n",
        "z_stat, p_value, z_crit, reject_null = two_tailed_z_test(sample_mean, population_mean, population_std, sample_size, alpha)\n",
        "\n",
        "print(f\"Z-statistic: {z_stat:.4f}\")\n",
        "print(f\"P-value: {p_value:.4f}\")\n",
        "print(f\"Critical Z-value: ±{z_crit:.4f}\")\n",
        "print(\"Reject Null Hypothesis\" if reject_null else \"Fail to Reject Null Hypothesis\")\n",
        "\n",
        "# Plotting the standard normal distribution and critical regions\n",
        "x = np.linspace(-4, 4, 1000)\n",
        "y = norm.pdf(x)\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.plot(x, y, label='Standard Normal Distribution')\n",
        "\n",
        "# Shade rejection regions\n",
        "plt.fill_between(x, 0, y, where=(x <= -z_crit), color='red', alpha=0.5, label='Rejection Region')\n",
        "plt.fill_between(x, 0, y, where=(x >= z_crit), color='red', alpha=0.5)\n",
        "\n",
        "# Mark the calculated z_stat\n",
        "plt.axvline(z_stat, color='blue', linestyle='--', linewidth=2, label=f'Z Statistic = {z_stat:.2f}')\n",
        "\n",
        "plt.title('Two-tailed Z-test Decision Regions')\n",
        "plt.xlabel('Z value')\n",
        "plt.ylabel('Probability Density')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "\n",
        "Q5.  Create a Python function that calculates and visualizes Type 1 and Type 2 errors during hypothesis testing\n",
        "\n",
        "Ans5. import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import norm\n",
        "from math import sqrt\n",
        "\n",
        "def visualize_type1_type2_errors(pop_mean, alt_mean, pop_std, sample_size, alpha=0.05):\n",
        "    \"\"\"\n",
        "    Visualizes Type 1 and Type 2 errors in a one-sample Z-test.\n",
        "\n",
        "    Parameters:\n",
        "    - pop_mean: Mean under null hypothesis (H0)\n",
        "    - alt_mean: Mean under alternative hypothesis (H1)\n",
        "    - pop_std: Population standard deviation\n",
        "    - sample_size: Sample size\n",
        "    - alpha: Significance level\n",
        "    \"\"\"\n",
        "\n",
        "    se = pop_std / sqrt(sample_size)\n",
        "\n",
        "    # Critical value for rejecting H0 (two-tailed)\n",
        "    z_crit = norm.ppf(1 - alpha/2)\n",
        "    crit_low = pop_mean - z_crit * se\n",
        "    crit_high = pop_mean + z_crit * se\n",
        "\n",
        "    # Define x range covering both distributions\n",
        "    x_min = min(pop_mean, alt_mean) - 4*se\n",
        "    x_max = max(pop_mean, alt_mean) + 4*se\n",
        "    x = np.linspace(x_min, x_max, 1000)\n",
        "\n",
        "    # PDFs under H0 and H1\n",
        "    pdf_null = norm.pdf(x, loc=pop_mean, scale=se)\n",
        "    pdf_alt = norm.pdf(x, loc=alt_mean, scale=se)\n",
        "\n",
        "    # Plot distributions\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.plot(x, pdf_null, label='Null Hypothesis (H0)', color='blue')\n",
        "    plt.plot(x, pdf_alt, label='Alternative Hypothesis (H1)', color='green')\n",
        "\n",
        "    # Shade rejection regions under H0 (Type 1 error areas)\n",
        "    plt.fill_between(x, 0, pdf_null, where=(x <= crit_low), color='red', alpha=0.3, label='Type 1 Error Region (α)')\n",
        "    plt.fill_between(x, 0, pdf_null, where=(x >= crit_high), color='red', alpha=0.3)\n",
        "\n",
        "    # Shade acceptance region under H1 (Type 2 error area)\n",
        "    plt.fill_between(x, 0, pdf_alt, where=(x > crit_low) & (x < crit_high), color='orange', alpha=0.3, label='Type 2 Error Region (β)')\n",
        "\n",
        "    # Vertical lines for critical values\n",
        "    plt.axvline(crit_low, color='red', linestyle='--', label='Critical Values')\n",
        "    plt.axvline(crit_high, color='red', linestyle='--')\n",
        "\n",
        "    plt.title('Type 1 and Type 2 Errors Visualization')\n",
        "    plt.xlabel('Sample Mean')\n",
        "    plt.ylabel('Probability Density')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "    # Calculate Type 2 error probability (β)\n",
        "    beta = norm.cdf(crit_high, loc=alt_mean, scale=se) - norm.cdf(crit_low, loc=alt_mean, scale=se)\n",
        "    power = 1 - beta\n",
        "\n",
        "    print(f\"Significance Level (Type 1 error α): {alpha}\")\n",
        "    print(f\"Type 2 Error (β): {beta:.4f}\")\n",
        "    print(f\"Test Power (1 - β): {power:.4f}\")\n",
        "\n",
        "# Example usage\n",
        "visualize_type1_type2_errors(\n",
        "    pop_mean=100,\n",
        "    alt_mea_\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "xZWcHM7GVGLf"
      }
    }
  ]
}