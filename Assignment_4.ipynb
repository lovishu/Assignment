{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "beeUERN2pBDB"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Questions and Answers\n",
        "\n",
        "\n",
        "Q1. Discuss the scenarios where multithreading is preferable to multiprocessing and scenarios where multiprocessing is a better choice  \n",
        "multiprocessing a better choice?\n",
        "Answer 1The choice between multithreading and multiprocessing in Python depends on the nature of the task, the architecture of the program, and the limitations of Python's Global Interpreter Lock (GIL). Below is a discussion of scenarios where each approach is preferable:\n",
        "\n",
        "1. Multithreading\n",
        "Multithreading involves running multiple threads (lightweight processes) within the same process. Threads share the same memory space, which makes it more efficient for certain tasks.\n",
        "\n",
        "When Multithreading is Preferable:\n",
        "I/O-Bound Tasks:\n",
        "\n",
        "Multithreading is ideal for programs that spend a significant amount of time waiting for input/output operations (e.g., reading/writing to files, network communication).\n",
        "\n",
        "Examples:\n",
        "Web scraping.\n",
        "Downloading multiple files concurrently.\n",
        "Chat applications or web servers handling multiple clients.\n",
        "2. Shared Memory Requirement:\n",
        "When threads need to communicate or share data efficiently, multithreading is more straightforward since all threads share the same memory space.\n",
        "Example:\n",
        "Real-time updates in GUI applications.\n",
        "Monitoring systems where threads constantly update shared variables.\n",
        "Low CPU Utilization:\n",
        "\n",
        "If the task doesn’t demand heavy computation and primarily involves lightweight operations, threads are sufficient.\n",
        "\n",
        "2. Multiprocessing\n",
        "Multiprocessing involves creating separate processes, each with its own memory space. It bypasses the GIL, allowing true parallelism.\n",
        "\n",
        "When Multiprocessing is Preferable:\n",
        "CPU-Bound Tasks:\n",
        "Tasks that involve heavy computation (e.g., numerical calculations, data analysis, machine learning) benefit from multiprocessing.\n",
        "Examples:\n",
        "Image or video processing.\n",
        "Large-scale matrix computations.\n",
        "Simulating complex models (e.g., Monte Carlo simulations).\n",
        "Summary\n",
        "Choose Multithreading:\n",
        "When tasks involve I/O-bound operations or lightweight operations.\n",
        "When memory sharing and fast communication between tasks are needed.\n",
        "For tasks where GIL limitations don’t affect performance (e.g., I/O-heavy tasks).\n",
        "Choose Multiprocessing:\n",
        "For CPU-bound tasks that benefit from parallelism across multiple cores.\n",
        "When tasks are independent and don’t require shared memory.\n",
        "To bypass the GIL and achieve true parallelism in computationally heavy tasks.\n",
        "\n",
        "\n",
        "Q2. Describe what a process pool is and how it helps in managing multiple processes efficiently.\n",
        "Ans2.A process pool is a collection of pre-initialized worker processes managed by a pool manager. It is a concept provided by Python’s multiprocessing module, which simplifies the creation and management of multiple processes. A process pool allows you to distribute tasks among a fixed number of worker processes, which can execute tasks in parallel.\n",
        "\n",
        "How Process Pools Work\n",
        "Instead of creating and destroying processes repeatedly for each task, a process pool maintains a pool of worker processes.\n",
        "Tasks are submitted to the pool, and the pool assigns these tasks to its workers.\n",
        "Once a worker completes a task, it becomes available for the next one, reducing overhead compared to creating new processes for each task\n",
        "\n",
        "Advantages of Using a Process Pool\n",
        "Efficient Resource Management:\n",
        "By reusing existing processes, the process pool minimizes the overhead of process creation and destruction.\n",
        "\n",
        "Parallelism:\n",
        "Process pools allow tasks to run concurrently, leveraging multiple CPU cores for true parallel execution.\n",
        "\n",
        "Simplified Code:\n",
        "The multiprocessing.Pool class provides high-level methods like map() and apply_async() for distributing tasks, reducing boilerplate code.\n",
        "\n",
        "Process Pool Methods\n",
        "map(func, iterable):\n",
        "Distributes the tasks in the iterable among the worker processes.\n",
        "Similar to Python's built-in map() but executes tasks in parallel.\n",
        "\n",
        "from multiprocessing import Pool\n",
        "\n",
        "def square(n):\n",
        "    return n * n\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    with Pool(4) as pool:  # Create a pool with 4 processes\n",
        "        results = pool.map(square, [1, 2, 3, 4, 5])\n",
        "    print(results)  # Output: [1, 4, 9, 16, 25]\n",
        "\n",
        "    def add(a, b):\n",
        "    return a + b\n",
        "apply(func, args):\n",
        "\n",
        "Executes a function with given arguments using one of the worker processes and returns the result.\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    with Pool(2) as pool:\n",
        "        result = pool.apply(add, (5, 3))  # Single task\n",
        "    print(result)  # Output: 8\n",
        "\n",
        "    apply_async(func, args):\n",
        "\n",
        "  Limitations of Process Pools\n",
        "\n",
        "  Inter-Process Communication Overhead:\n",
        "Processes don’t share memory, so data must be serialized and passed between processes, which can be slow.\n",
        "Not Suitable for I/O-Bound Tasks:\n",
        "\n",
        "For I/O-bound tasks, multithreading is often more efficient.\n",
        "Fixed Number of Processes:\n",
        "\n",
        "The pool size is fixed when created, which might limit scalability if more resources become available dynamically.\n",
        "\n",
        "\n",
        "Q3. Explain what multiprocessing is and why it is used in Python programs.\n",
        "Ans3. Multiprocessing is a programming technique in which multiple processes run simultaneously to perform tasks in parallel. Each process operates independently and has its own memory space. This technique leverages multiple CPU cores to execute tasks concurrently, allowing Python programs to perform parallel processing and bypass the limitations of the Global Interpreter Lock (GIL).\n",
        "\n",
        "In Python, the multiprocessing module provides support for spawning and managing processes. It is particularly useful for CPU-bound tasks that require heavy computation.\n",
        "\n",
        "Why Use Multiprocessing in Python?\n",
        "Python’s Global Interpreter Lock (GIL) restricts the execution of multiple threads in the same Python process, limiting multithreading’s ability to achieve true parallelism for CPU-bound tasks. Multiprocessing overcomes this limitation by creating separate processes, each with its own Python interpreter, which can execute tasks concurrently.\n",
        "\n",
        "Key Benefits of Multiprocessing:\n",
        "True Parallelism:\n",
        "Multiprocessing enables tasks to run on multiple CPU cores simultaneously, achieving true parallel execution.\n",
        "\n",
        "Bypassing the GIL:\n",
        "Each process runs in its own memory space, allowing Python programs to perform parallel computation without interference from the GIL.\n",
        "\n",
        "Improved Performance for CPU-Bound Tasks: Tasks involving heavy computation (e.g., numerical simulations, data analysis, machine learning) benefit from multiprocessing by utilizing all available CPU cores.\n",
        "\n",
        "Scalability:\n",
        "Multiprocessing makes it easier to scale programs to handle larger workloads by distributing tasks across multiple processes.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Q4. Write a Python program using multithreading where one thread adds numbers to a list, and another thread removes numbers from the list. Implement a mechanism to avoid race conditions using  threading.Lock.\n",
        "\n",
        "Ans4.Below is a Python program using multithreading to demonstrate adding numbers to a list in one thread and removing numbers from the same list in another thread. A threading.Lock is used to avoid race conditions when both threads access the shared list.\n",
        "\n",
        "Python Code: Adding and Removing Numbers with Lock\n",
        "\n",
        "import threading\n",
        "import time\n",
        "\n",
        "# Shared resource\n",
        "shared_list = []\n",
        "\n",
        "# Lock to avoid race conditions\n",
        "list_lock = threading.Lock()\n",
        "\n",
        "def add_numbers():\n",
        "    \"\"\"Thread function to add numbers to the list.\"\"\"\n",
        "    for i in range(1, 6):\n",
        "        with list_lock:  # Acquire lock\n",
        "            shared_list.append(i)\n",
        "            print(f\"Added: {i}, List: {shared_list}\")\n",
        "        time.sleep(0.5)  # Simulate delay\n",
        "\n",
        "def remove_numbers():\n",
        "    \"\"\"Thread function to remove numbers from the list.\"\"\"\n",
        "    for _ in range(1, 6):\n",
        "        with list_lock:  # Acquire lock\n",
        "            if shared_list:\n",
        "                removed = shared_list.pop(0)\n",
        "                print(f\"Removed: {removed}, List: {shared_list}\")\n",
        "        time.sleep(1)  # Simulate delay\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Create threads\n",
        "    adder_thread = threading.Thread(target=add_numbers)\n",
        "    remover_thread = threading.Thread(target=remove_numbers)\n",
        "\n",
        "    # Start threads\n",
        "    adder_thread.start()\n",
        "    remover_thread.start()\n",
        "\n",
        "    # Wait for threads to complete\n",
        "    adder_thread.join()\n",
        "    remover_thread.join()\n",
        "\n",
        "    print(\"Final List:\", shared_list)\n",
        "\n",
        "Explanation of the Code\n",
        "\n",
        "Shared Resource:\n",
        "\n",
        "shared_list is the shared list accessed by both threads.\n",
        "Lock Mechanism:\n",
        "\n",
        "Thread Functions:add_numbers: Adds numbers (1 to 5) to the list with a slight delay (time.sleep) to simulate real-world conditions.\n",
        "\n",
        "remove_numbers: Removes numbers from the list if it is not empty, with a slightly longer delay (time.sleep).\n",
        "\n",
        "Thread Synchronization:\n",
        "\n",
        "with list_lock: Ensures that only one thread can execute the critical section (code accessing the shared list) at any given time.\n",
        "\n",
        "\n",
        "Main Program:\n",
        "\n",
        "Added: 1, List: [1]\n",
        "Removed: 1, List: []\n",
        "Added: 2, List: [2]\n",
        "Removed: 2, List: []\n",
        "Added: 3, List: [3]\n",
        "Removed: 3, List: []\n",
        "Added: 4, List: [4]\n",
        "Removed: 4, List: []\n",
        "Added: 5, List: [5]\n",
        "Removed: 5, List: []\n",
        "Final List: []\n",
        "\n",
        "\n",
        "Q5. Describe the methods and tools available in Python for safely sharing data between threads and processes\n",
        "\n",
        "Ans5. Safely Sharing Data in Python\n",
        "Sharing data between threads and processes in Python requires special mechanisms to ensure safety and avoid issues such as race conditions or deadlocks. Python provides various methods and tools to manage shared data safely.\n",
        "\n",
        "1. Sharing Data Between Threads\n",
        "Threads in Python share the same memory space, making data sharing easier but prone to race conditions. The following tools help\n",
        "\n",
        "Q 6. Discuss why it’s crucial to handle exceptions in concurrent programs and the techniques available for doing so\n",
        "\n",
        "Ans 6.In concurrent programming (using threads or processes), handling exceptions is more complex but equally important as in sequential programs. If exceptions are not managed properly, they can cause:\n",
        "\n",
        "Partial Failures: An exception in one thread or process may leave shared resources (e.g., files, memory, locks) in an inconsistent state, affecting other threads or processes.\n",
        "\n",
        "Deadlocks: If a thread or process encounters an exception without releasing a lock, it can lead to deadlocks, causing the entire program to hang.\n",
        "\n",
        "Unpredictable Behavior: Concurrent programs operate asynchronously, making it difficult to trace errors. Unhandled exceptions can make debugging extremely challenging.\n",
        "Program Crashes: An unhandled exception in the main thread or process may terminate the entire program, even if other threads or processes are running correctly.\n",
        "Exceptions may interrupt operations like writing to a database or file, leading to corrupted or incomplete data.\n",
        "Techniques for Exception Handling in Concurrent Programs\n",
        "1. Using try-except Blocks\n",
        "The most basic and widely used method is wrapping critical sections of code in try-except blocks to catch and handle exceptions.\n",
        "python\n",
        "import threading\n",
        "\n",
        "def thread_task():\n",
        "    try:\n",
        "        result = 10 / 0  # Intentional error\n",
        "    except ZeroDivisionError as e:\n",
        "        print(f\"Exception in thread: {e}\")\n",
        "\n",
        "thread = threading.Thread(target=thread_task)\n",
        "thread.start()\n",
        "thread.join()\n",
        "\n",
        "2. Handling Exceptions in Threads\n",
        "Threads run independently, and exceptions raised in one thread don’t propagate to the main thread. Use these approaches to handle exceptions:\n",
        "\n",
        "Custom Wrapper for Thread Functions:\n",
        "\n",
        "Wrap the thread's task in a try-except block to ensure exceptions are logged or managed.\n",
        "python\n",
        "def thread_task():\n",
        "    try:\n",
        "        # Code that might raise an exception\n",
        "        raise ValueError(\"An error occurred\")\n",
        "    except Exception as e:\n",
        "        print(f\"Caught exception: {e}\")\n",
        "\n",
        "threading.Thread(target=thread_task).start()\n",
        "\n",
        "3. Handling Exceptions in Processes\n",
        "In multiprocessing, each process has its own memory space, and exceptions do not propagate to the parent process. Use these methods:\n",
        "\n",
        "Similar to threads, wrap the task code in a try-except block.\n",
        "python\n",
        "from multiprocessing import Process\n",
        "\n",
        "def process_task():\n",
        "    try:\n",
        "        raise ValueError(\"Process error\")\n",
        "    except Exception as e:\n",
        "        print(f\"Process exception: {e}\")\n",
        "\n",
        "process = Process(target=process_task)\n",
        "process.start()\n",
        "process.join()\n",
        "\n",
        "Using multiprocessing.Pool Exception Handling:\n",
        "\n",
        "Use the Pool.apply_async() method with a callback or error callback to handle exceptions.\n",
        "python\n",
        "\n",
        "from multiprocessing import Pool\n",
        "\n",
        "def process_task(n):\n",
        "    if n == 0:\n",
        "        raise ValueError(\"Invalid value\")\n",
        "    return n * n\n",
        "\n",
        "def error_handler(e):\n",
        "    print(f\"Error: {e}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    with Pool(4) as pool:\n",
        "        results = [pool.apply_async(process_task, (i,), error_callback=error_handler) for i in range(5)]\n",
        "\n",
        "        # Wait for all tasks to complete\n",
        "        for result in results:\n",
        "            try:\n",
        "                print(result.get())\n",
        "            except Exception as e:\n",
        "                print(f\"Handled in main: {e}\"\n",
        "\n",
        "\n",
        "4. Using Context Managers When working with locks or other resources, use context managers (with) to ensure proper cleanup even in the event of exceptions.\n",
        "import threading\n",
        "\n",
        "lock = threading.Lock()\n",
        "\n",
        "def task_with_lock():\n",
        "    try:\n",
        "        with lock:\n",
        "            # Critical section\n",
        "            raise ValueError(\"Some error\")\n",
        "    except Exception as e:\n",
        "        print(f\"Exception while holding lock: {e}\")\n",
        "\n",
        "thread = threading.Thread(target=task_with_lock)\n",
        "thread.start()\n",
        "thread.join()\n",
        "\n",
        "Key Considerations for Exception Handling\n",
        "Isolate Critical Sections:\n",
        "Use try-except blocks only where necessary to avoid masking unrelated issues.\n",
        "Log Exceptions:\n",
        "Always log exceptions for debugging and monitoring purposes.\n",
        "Cleanup Resources:\n",
        "Ensure resources like locks, files, or sockets are released properly using context managers or finally blocks.\n",
        "Propagate Exceptions When Necessary:\n",
        "Propagate exceptions to the parent thread or process for centralized handling.\n",
        "\n",
        "\n",
        "Q7. Create a program that uses a thread pool to calculate the factorial of numbers from 1 to 10 concurrently. Use concurrent.futures.ThreadPoolExecutor to manage the threads.\n",
        "Ans7. Here’s a Python program that uses the concurrent.futures.ThreadPoolExecutor to calculate the factorial of numbers from 1 to 10 concurrently. This makes use of thread pooling for efficient thread management.\n",
        "\n",
        "Python Code: Factorial Calculation with Thread Pool\n",
        "\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "import math\n",
        "\n",
        "def calculate_factorial(n):\n",
        "    \"\"\"Function to calculate the factorial of a given number.\"\"\"\n",
        "    print(f\"Calculating factorial of {n}\")\n",
        "    return math.factorial(n)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    numbers = range(1, 11)  # Numbers from 1 to 10\n",
        "\n",
        "    # Create a ThreadPoolExecutor\n",
        "    with ThreadPoolExecutor(max_workers=5) as executor:\n",
        "        # Submit tasks to the thread pool\n",
        "        results = executor.map(calculate_factorial, numbers)\n",
        "\n",
        "    # Print the results\n",
        "    for num, factorial in zip(numbers, results):\n",
        "        print(f\"Factorial of {num}: {factorial}\")\n",
        "Explanation of the Code\n",
        "Function calculate_factorial:\n",
        "Accepts a number n and returns its factorial using math.factorial.\n",
        "\n",
        "Thread Pool Management:\n",
        "ThreadPoolExecutor manages a pool of threads.\n",
        "max_workers=5: Limits the thread pool to a maximum of 5 threads.\n",
        "\n",
        "Submitting Tasks:\n",
        "executor.map(calculate_factorial, numbers): Automatically assigns numbers from numbers to threads in the pool.\n",
        "Concurrent Execution:\n",
        "Multiple threads compute factorials concurrently, making the program efficient.\n",
        "Output Handling:\n",
        "\n",
        "The results of executor.map are collected and printed along with the input numbers.\n",
        "\n",
        "\n",
        "Q8.Create a Python program that uses multiprocessing.Pool to compute the square of numbers from 1 to 10 in parallel. Measure the time taken to perform this computation using a pool of different sizes (e.g., 2, 4, 8 procesess\n",
        "\n",
        "Ans 8.Here’s a Python program that uses the multiprocessing.Pool to compute the square of numbers from 1 to 10 in parallel. The program measures the time taken for the computation with different pool sizes (e.g., 2, 4, 8 processes).\n",
        "\n",
        "from multiprocessing import Pool\n",
        "import time\n",
        "\n",
        "def compute_square(n):\n",
        "    \"\"\"Function to compute the square of a number.\"\"\"\n",
        "    return n * n\n",
        "\n",
        "def measure_execution_time(pool_size):\n",
        "    \"\"\"Measure the time taken to compute squares using a Pool of given size.\"\"\"\n",
        "    numbers = range(1, 11)  # Numbers from 1 to 10\n",
        "\n",
        "    # Start the timer\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Create a pool with the specified number of processes\n",
        "    with Pool(pool_size) as pool:\n",
        "        results = pool.map(compute_square, numbers)\n",
        "\n",
        "    # End the timer\n",
        "    end_time = time.time()\n",
        "\n",
        "    # Return results and time taken\n",
        "    return results, end_time - start_time\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    pool_sizes = [2, 4, 8]  # Different pool sizes to test\n",
        "\n",
        "    for pool_size in pool_sizes:\n",
        "        print(f\"\\nUsing a pool of size {pool_size}:\")\n",
        "        results, time_taken = measure_execution_time(pool_size)\n",
        "        print(f\"Squares: {results}\")\n",
        "        print(f\"Time taken: {time_taken:.4f} seconds\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "4hKWQ5w3pFcD"
      }
    }
  ]
}